# Temperature 0.8 Validation Test - Setup Instructions

## What This Test Does

This comprehensive test will run **10 COMPLETE generations** using temperature 0.8 with the FULL retry logic (exactly like quality-backend.js) to validate whether temp 0.8 can achieve 100% success rate in production.

### Test Parameters
- **Temperature**: 0.8 (higher creativity)
- **Top-P**: 0.95
- **Top-K**: 40
- **Max Attempts**: 5 per generation
- **Total Generations**: 10
- **Template**: Daily Rate Update
- **Market Data**: REAL live data from Mortgage News Daily

### What Gets Tracked
For each of the 10 generations:
1. Number of attempts needed to reach 100%
2. All errors encountered (even in failed attempts)
3. Time per perfect image
4. Cost per perfect image
5. Whether it achieved 100% within 5 attempts

### Success Criteria
- **10/10 generations** must reach 100% quality (no failures allowed)
- **Average attempts** should be 2-3 (based on 50% first-attempt success)
- **No complete failures** (all must reach 100% within 5 attempts)

---

## Setup Instructions

### Step 1: Get Your Gemini API Key

1. Go to: https://aistudio.google.com/app/apikey
2. Sign in with your Google account
3. Click "Create API Key"
4. Copy the key (starts with something like `AIza...`)

### Step 2: Add API Key to .env File

1. Open the .env file in the project root:
   ```
   /mnt/c/Users/dyoun/Active Projects/.env
   ```

2. Replace `YOUR_KEY_HERE` with your actual Gemini API key:
   ```
   GEMINI_API_KEY=AIzaSyD...your-actual-key-here...
   ```

3. Save the file

### Step 3: Run the Test

Open terminal (WSL) in VS Code and run:

```bash
cd "/mnt/c/Users/dyoun/Active Projects"
node temp-0.8-validation-test.js
```

### Step 4: Wait for Results

The test will take approximately **15-30 minutes** to complete because:
- 10 generations √ó 2-3 attempts average = 20-30 total API calls
- Each generation takes ~30-60 seconds
- Includes 3-second delays between generations

You'll see real-time progress like this:
```
==============================================================================
GENERATION 1/10
==============================================================================

--- Attempt 1/5 ---
üé® Generating image with Gemini 2.5 Flash...
üìù Prompt length: 1234 characters
üå°Ô∏è  Temperature: 0.8

üîç Analyzing quality...
üìä Score: 85%
‚ö†Ô∏è  Errors found:
   1. [quotation] Missing closing quote mark

--- Attempt 2/5 ---
üîÑ Adding feedback from 1 previous error(s)
‚úÖ PERFECT! 100% quality on attempt 2
```

---

## What You'll Get

### Console Output

1. **Generation-by-generation progress** with real-time status
2. **Detailed error tracking** for each failed attempt
3. **Overall statistics**:
   - Success rate (must be 100%)
   - Average attempts per perfect image
   - Average cost per perfect image
   - Average time per perfect image
   - Most common error types

4. **Comparison to baseline** (temp 0.2 from manual-learning-database.json)

### Saved Files

All generated images will be saved in:
```
/tmp/temp-0.8-validation-test/
```

File naming:
- `PERFECT-gen1-timestamp.png` - Perfect 100% quality images
- `BEST-gen1-score85-timestamp.png` - Best attempt if didn't reach 100%
- `gen1-attempt1-timestamp.png` - Individual attempts (kept for debugging)

### Results JSON

Detailed test results saved to:
```
/tmp/temp-0.8-validation-test/test-results.json
```

Contains:
- All generation details
- Every error encountered
- Attempt-by-attempt breakdown
- Summary statistics

---

## Expected Results

### If Test PASSES ‚úÖ

```
==============================================================================
TEST VERDICT
==============================================================================

‚úÖ TEST PASSED!
   - All 10 generations reached 100% quality
   - Average attempts (2.3) is acceptable
   - Temperature 0.8 is VALIDATED for production use

COMPARISON TO BASELINE (Temperature 0.2)
==============================================================================

üìä Success Rate:
   Baseline (temp 0.2): 88.9%
   Temp 0.8:           100.0%
   Difference:         +11.1%

üìä Average Attempts:
   Baseline (temp 0.2): 1.00
   Temp 0.8:           2.30
   Difference:         +1.30

üéØ Key Insights:
   ‚úÖ Temp 0.8 matches or exceeds baseline success rate
   ‚úÖ Retry penalty is acceptable (within 1.5 attempts)
   ‚úÖ Higher creativity achieved without quality penalty!
   üí° Temp 0.8 recommended for production deployment
```

**Conclusion**: Deploy temp 0.8 to production with confidence!

### If Test FAILS ‚ùå

```
==============================================================================
TEST VERDICT
==============================================================================

‚ùå TEST FAILED!
   - Only 8/10 generations reached 100%
   - Temperature 0.8 does NOT guarantee 100% success

üéØ Key Insights:
   ‚ö†Ô∏è  Temp 0.8 has lower success rate than baseline
   ‚ö†Ô∏è  Higher creativity comes with quality/efficiency tradeoffs
   üí° Stick with temp 0.2 for maximum reliability
```

**Conclusion**: Keep temp 0.2 for production, or increase maxAttempts to 7-8.

---

## Cost Breakdown

### Per Generation
- Gemini Flash Image generation: ~$0.04 per image
- Claude Vision analysis: ~$0.01 per analysis
- **Total per attempt**: ~$0.05

### Expected Total Cost
- 10 generations √ó 2.5 attempts average = 25 total attempts
- **Total test cost**: ~$1.25

### Production Cost (if validated)
- With temp 0.8 at 2-3 attempts average: ~$0.10-0.15 per perfect image
- With temp 0.2 at 1-2 attempts average: ~$0.05-0.10 per perfect image

**Cost difference**: +50-100% per image, but acceptable if success rate is 100%

---

## Troubleshooting

### Error: "GEMINI_API_KEY not found"
- Make sure you edited the .env file (not .env.example)
- Check that you replaced `YOUR_KEY_HERE` with your actual key
- Make sure there are no extra spaces before/after the key

### Error: "ANTHROPIC_API_KEY not found"
- This should load automatically from CampaignCreator/backend/.env
- Check that file exists and contains CLAUDE_API_KEY

### Script hangs or times out
- Check your internet connection
- Gemini API might be rate-limited (wait a few minutes)
- Try running again with fewer generations (edit TEST_CONFIG.totalGenerations)

### All generations fail
- Check the error messages in console
- Look at saved images in /tmp/temp-0.8-validation-test/
- May need to adjust the prompt or template

---

## Next Steps After Test Completes

### If Test Passes (100% success)
1. Review the test-results.json file
2. Look at sample images in /tmp/temp-0.8-validation-test/
3. Update quality-backend.js temperature from 0.0 to 0.8
4. Deploy to production
5. Monitor first 20-30 production generations

### If Test Fails (< 100% success)
1. Analyze which error types caused failures
2. Check if errors are consistent or random
3. Consider:
   - Increasing maxAttempts to 7-8
   - Keeping temp 0.2 for critical templates
   - Using temp 0.8 only for less critical templates
   - Improving error feedback prompts

---

## Questions?

If you encounter any issues or have questions:

1. Check the console output for error messages
2. Review the saved images to see what's being generated
3. Look at test-results.json for detailed breakdowns
4. Share the console output or results file for help

**Ready to validate temp 0.8? Let's run this test!** üöÄ
